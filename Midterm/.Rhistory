library(swirl)
install.packages("swirl")
library(swirl)
swirl()
install_from_swirl("Getting_and_Cleaning_Data")
swirl()
swirl()
install_from_swirl("Regression_Models")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageversion("dplyr")
packageVersion("dplyr")
cran <- tbl_df(tbl_df(data))
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
library(swirl)
swirl()
select(cran, -time)
-5:20
-(-5:20)
-(5:20)
select(cran, -(5:20))
select(cran, -(X:size))
filter(cran, package == "swirl")
exit()
quit()
library(swirl)
ls()
swirl()
swirl()
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "India")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2" | country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, r_version == !is.na)
filter(cran, r_version == !is.na())
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3,size_mb = size / 2^20)
mutate(cran3,size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size_gb - 1000)
mutate(cran3, correct_size = size - 1000)
mutate(cran3, correct_size = size + 1000)
exit()
exit
quit(0)
libarary(swirl)
library(swirl)
swirl()
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
group_by()
?group_by
by_package <- group_by(cran, package)
by_package
summarize(cran, mean(size))
summarize(by_package, mean(size))
library(swirl)
swirl()
submit()
tbl, pack_sum
pack_sum
yelp_user_summary <- read.csv("C:/Users/turman/Desktop/Big Data/yelp_user_summary.csv")
View(yelp_user_summary)
yelp_user_summary
mean <- mean(yelp_user_summary$average_stars)
mean
yelp_user_summary$yelping_since > 2009
count(yelp_user_summary$yelping_since > 2009)
clear
head(yelp_user_summary)
library(stats)
?str
data(yelp_user_summary)
yelp_user_summary <- read.csv("C:/Users/turman/Desktop/Big Data/yelp_user_summary.csv")
View(yelp_user_summary)
str(yelp_user_summary)
summary(yelp_user_summary)
yelpstat <- c(yelp_user_summary$review_count, yelp_user_summary$fans, yelp_user_summary$average_stars)
summary(yelpstat)
yelpstat
with(yelp_user_summary, plot(review_count, average_stars))
with(yelp_user_summary, plot(fans, average_stars))
with(yelp_user_summary, plot(review_count, fans))
with(yelp_user_summary, plot(fans, review_count))
with(yelp_user_summary, plot(yelping_since, review_count))
with(yelp_user_summary, plot(yelping_since, fans))
with(yelp_user_summary, plot(yelping_since, average_stars))
with(yelp_user_summary, plot(average_stars, yelping_since))
counts <- table(yelp_user_summary$average_stars)
barplot(counts, main="average_stars",
xlab="Number of average")
counts
summary(counts)
with(yelp_user_summary, plot(counts))
with(yelp_user_summary, plot(average_stars, fans))
av1 = rnorm(100); av2 = rt(100,df=3)
plot(density(av1));plot(density(av2))
shapiro.test(av1); shapiro.test(av2)
qqnorm(av1);qqline(av1,col =2)
qqnorm(av2);qqline(av2,col =2)
summary(yelp_user_summary)
qqnorm(yelp_user_summary$review_count,yelp_user_summary$average_stars)
qqnorm(yelp_user_summary$review_count)
review_count <- yelp_user_summary$review_count
average_stars <- yelp_user_summary$average_stars
qqnorm(review_count$average_stars)
qqnorm(review_count, average_stars)
?qqnorm
qqnorm(yelp_user_summary$average_stars)
qqnorm(yelp_user_summary$review_count)
summary(yelp_user_summary)
qqnorm(yelp_user_summary$fans)
yelp <- yelp_use_summary
library(swirl)
swirl()
View(cran2)
install.packages("lpSolveAPI")
install.packages("gridExtra")
library(lpSolveAPI)
#used for result visualization
library(ggplot2)
library(reshape)
library(gridExtra)
#define the datasets
train<-data.frame(wagon=c('w1','w2','w3'), weightcapacity=c(10,8,12), spacecapacity=c(5000,4000,8000))
cargo<-data.frame(type=c('c1','c2','c3','c4'), available=c(18,10,5,20), volume=c(400,300,200,500),profit=c(2000,2500,5000,3500))
install.packages("ggplot2")
install.packages("dplyr")
install.packages("reshape")
iris
head(iris)
install.packages(ggvis)
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points() - Read more at: http://scl.io/raimhAbo#gs.dPgEnT8
installed.packages("ggvis")
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points() - Read more at: http://scl.io/raimhAbo#gs.dPgEnT8
installed.packages("class")
installed.packages("caret")
install.packages("caret")
install.packages("class")
install.packages("ggvis")
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points() - Read more at: http://scl.io/raimhAbo#gs.dPgEnT8
install.packages("randomForest")
library(caret)
library(randomForest)
Titanic
summary(Titanic)
head(Titanic)
install.packages("Rglpk")
install.packages("Rsymphony")
install.packages("tdyr")
install.packages("tidyr")
obj . fun <- c(20 , 60)
constr <- matrix (c(30 , 20 , 5 , 10 , 1 , 1) , ncol = 2 , byrow =
TRUE )
constr . dir <- c(" <=", " <=", " >=")
rhs <- c(2700 , 850 , 95)
10 #solving model
prod . sol <- lp ("max", obj . fun , constr , constr .dir , rhs ,
compute . sens = TRUE )
library(lpSolveAPI)
obj.fun <- c(20 , 60)
constr <- matrix (c(30 , 20 , 5 , 10 , 1 , 1) , ncol = 2 , byrow =TRUE )
constr.dir <- c(" <=", " <=", " >=")
rhs <- c(2700 , 850 , 95)
10 #solving model
prod.sol <- lp ("max", obj.fun , constr , constr.dir, rhs ,compute . sens = TRUE )
obj.fun <- c(20 , 60)
constr <- matrix (c(30 , 20 , 5 , 10 , 1 , 1) , ncol = 2 , byrow =TRUE )
constr.dir <- c(" <=", " <=", " >=")
rhs <- c(2700 , 850 , 95)
10 #solving model
prod.sol <- lp ("max", obj.fun , constr , constr.dir, rhs ,compute.sens = TRUE )
library(lpSolve)
install.packages("lpSolve")
library(lpSolve)
obj.fun <- c(20 , 60)
constr <- matrix (c(30 , 20 , 5 , 10 , 1 , 1) , ncol = 2 , byrow =TRUE )
constr.dir <- c(" <=", " <=", " >=")
rhs <- c(2700 , 850 , 95)
10 #solving model
prod.sol <- lp ("max", obj.fun , constr , constr.dir, rhs ,compute.sens = TRUE )
5/37
37/43
37/42
setwd("C:/Users/turman/Desktop/Q2/804w/Midterm")
library(leaps) # Exhaustive search for the best subsets of the variables in x for predicting y
library(e1071) # Skewness and Kurtosis
library(broom) # For residual analysis
library(ggplot2) # Plotting
library(sqldf) #to reformat the data
library(dplyr) #data prep
library(reshape2) #restructuring data
library(psych) #for descriptive stats
library(car) # levenes test
install.packages("ggplot2")
library(ggplot2)
unzip("data/On_Time_On_Time_Performance_2016_8.zip",exdir="data/")
setwd("C:/Users/turman/Desktop/Q2/804w/Midterm")
unzip("data/On_Time_On_Time_Performance_2016_8.zip",exdir="data/")
unzip("data/On_Time_On_Time_Performance_2016_8.zip")
install.packages("data.table")
flights <- read.csv("On_Time_On_Time_Performance_2016_8.csv")
library(data.table) #to load data
flights.dt <- fread("On_Time_On_Time_Performance_2016_8.csv")
str(flights)
str(flights.dt)
View(flights.dt)
flights <- fread("On_Time_On_Time_Performance_2016_8.csv")
str(flights.dt)
author <- "Jim Turman"
student.id <- "00935936"
library(leaps) # Exhaustive search for the best subsets of the variables in x for predicting y
library(e1071) # Skewness and Kurtosis
library(broom) # For residual analysis
library(ggplot2) # Plotting
library(sqldf) #to reformat the data
library(dplyr) #data prep
library(reshape2) #restructuring data
library(psych) #for descriptive stats
library(car) # levenes test
library(data.table) #to load data reads better than the read.csv function
flights <- fread("On_Time_On_Time_Performance_2016_8.csv")
flights <- flights[,-65:110]
flights <- flights[1:64]
flights <- fread("On_Time_On_Time_Performance_2016_8.csv")
View(flights.dt)
author <- "Jim Turman"
student.id <- "00935936"
library(leaps) # Exhaustive search for the best subsets of the variables in x for predicting y
library(e1071) # Skewness and Kurtosis
library(broom) # For residual analysis
library(ggplot2) # Plotting
library(sqldf) #to reformat the data
library(dplyr) #data prep
library(reshape2) #restructuring data
library(psych) #for descriptive stats
library(car) # levenes test
library(data.table) #to load data reads better than the read.csv function
flights <- fread("On_Time_On_Time_Performance_2016_8.csv")
flights <- flights[c(1:65)]
head(flights)
library(leaps) # Exhaustive search for the best subsets of the variables in x for predicting y
library(e1071) # Skewness and Kurtosis
library(broom) # For residual analysis
library(ggplot2) # Plotting
library(sqldf) #to reformat the data
library(dplyr) #data prep
library(reshape2) #restructuring data
library(psych) #for descriptive stats
library(car) # levenes test
library(data.table) #to load data reads better than the read.csv function
flights[is.na(flights)] <- 0
head(flights)
flights <- sqldf("select * from flights where Origin = 'SFO'")
head(flights)
flights <- fread("On_Time_On_Time_Performance_2016_8.csv")
View(flights)
flights.sfo <- sqldf("select * from flights where Origin = 'SFO'")
head(flights)
flights.airline <- sqldf("select * from flights.sfo group by Carrier")
flights.sfo <- sqldf("select * from flights where Origin = 'SFO' group by Carrier")
print(flights.sfo)
flights.sfo[is.na(flights.sfo)] <- 0
print(flights.sfo)
View(flights.sfo)
describe(flights.sfo)
flights_sfo <- sqldf("select * from flights where Origin = 'SFO' group by Carrier")
flights_sfo[is.na(flights_sfo)] <- 0
flights.desc <- sqldf("select DepDelay, CarrierDelay, WeatherDelay, NASDelay,
SecurityDelay, LateAircraftDelay FROM flights_sfo")
describe(flights.desc)
View(flights.desc)
View(flights_sfo)
flights.desc <- sqldf("select DepDelay, CarrierDelay, WeatherDelay, NASDelay,
SecurityDelay, LateAircraftDelay FROM flights")
describe(flights.desc)
