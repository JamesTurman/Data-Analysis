fit.1 <- lm(data = wait.melt)
print('fun')
install.packages("rvest")
library(rvest)
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
lego_movie <- read.html("http://www.imdb.com/title/tt1490017/")
lego_movie <- html("http://www.imdb.com/title/tt1490017/")
Deprecated?
?Deprecated
lego_movie <- read_html("http://www.imdb.com/title/tt1490017/")
lego_movie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
lego_movie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
head(lego_movie)
install.packages("Rglpk")
install.packages("lpSolve")
install.packages("Rsymphony")
library("Rglpk")
library("lpSolve")
library(Rsymphony)
MIN z = 20P1+60P2
install.packages("lpSoleAPI")
install.packages("lpSolveAPI")
obj.fun <- c(20,60)
constr <- matrix(c(30,20,5,10,1,1), ncol = 2, byrow = TRUE)
library(lpSolve)
constr.dir <- c("<=","<=",">=")
rhs <- c(2700,850,95)
prod.sol <- lp("max", obj.fun,constr,constr.dir,rhs,compute.sens = TRUE)
prod.sol$duals.from
prod.sol$duals.to
prod.sol$sens.coef.from
prod.sol$sens.coef.to
prod.sol$obj.val
prod.sol$solution
prod.sol$duals
obj.fun <- c(8,6,3,2,4,9)
m <- 2
n <- 3
constr <- matrix(0,n+m,n*m)
for(i in 1:m){}
for(i in 1:m){}
library ( lpSolve )
#defining parameters
#origins run i in 1:m
#destinations run j in 1:n
obj.fun <- c(8 , 6 , 3 , 2 , 4 , 9)
m <- 2
n <- 3
constr <- matrix (0 , n +m , n*m )
for ( i in 1: m ) {
for ( j in 1: n ) {
constr [i , n*(i -1) + j ] <- 1
constr [ m +j , n*(i -1) + j ] <- 1
}
}
constr.dir <- c(rep(" <=", m ) , rep(" >=", n ) )
rhs <- c(70 , 40 , 40 , 35 , 25)
#solving LP model
prod.trans <- lp (" min", obj.fun , constr , constr.dir , rhs ,
compute.sens = TRUE )
#LP solution
prod.trans $obj.val
sol <- matrix ( prod.trans $ solution , m , n , byrow = TRUE )
prod.trans $ duals
#sensitivity analysis of LP
prod.trans $ duals.from
prod.trans $ duals.to
prod.trans $ sens.coef.from
prod.trans $ sens.coef.to
library ( lpSolve )
#defining parameters
#origins run i in 1:m
#destinations run j in 1:n
obj.fun <- c(8 , 6 , 3 , 2 , 4 , 9)
m <- 2
n <- 3
constr <- matrix (0 , n +m , n*m )
for ( i in 1: m ) {
for ( j in 1: n ) {
constr [i , n*(i -1) + j ] <- 1
constr [ m +j , n*(i -1) + j ] <- 1
}
}
constr.dir <- c(rep(" <=", m ) , rep(" >=", n ) )
rhs <- c(70 , 40 , 40 , 35 , 25)
#solving LP model
prod.trans <- lp (" min", obj.fun , constr , constr.dir , rhs ,
compute.sens = TRUE )
#LP solution
prod.trans$obj.val
sol <- matrix ( prod.trans$solution , m , n , byrow = TRUE )
prod.trans$duals
#sensitivity analysis of LP
prod.trans$duals.from
prod.trans$duals.to
prod.trans$sens.coef.from
prod.trans$sens.coef.to
constr <- matrix (0 , n +m , n*m )
for ( i in 1: m ) {
for ( j in 1: n ) {
constr [i , n*(i -1) + j ] <- 1
constr [ m +j , n*(i -1) + j ] <- 1
}
}
constr.dir <- c(rep(" <=", m ) , rep(" >=", n ) )
rhs <- c(70 , 40 , 40 , 35 , 25)
prod.trans <- lp(" min", obj.fun , constr, constr.dir, rhs,
compute.sens = TRUE )
prod.trans <- lp("min", obj.fun , constr, constr.dir, rhs,
compute.sens = TRUE )
constr.dir <- c(rep("<=", m ) , rep(">=", n ) )
rhs <- c(70 , 40 , 40 , 35 , 25)
prod.trans <- lp("min", obj.fun , constr, constr.dir, rhs,
compute.sens = TRUE )
prod.trans$obj.val
sol <- matrix ( prod.trans$solution , m , n , byrow = TRUE )
prod.trans$duals
#sensitivity analysis of LP
prod.trans$duals.from
prod.trans$duals.to
prod.trans$sens.coef.from
prod.trans$sens.coef.to
prod.trans
prod.sol
return(results)
rhs
Minimize
cost: 12q1
prod.sol
prod.trans
constr.dir
setwd("C:/Users/jaturman/Desktop/data analysis/ops804/Midterm/data")
time <- read.csv("On_Time_On_Time_Performance_2016_8.csv")
library(leaps) # Exhaustive search for the best subsets of the variables in x for predicting y
library(e1071) # Skewness and Kurtosis
library(broom) # For residual analysis
library(ggplot2) # Plotting
library(sqldf) #to reformat the data
library(dplyr) #data prep
library(reshape2) #restructuring data
library(psych) #for descriptive stats
library(car) # levenes test
#read in data
delay <- sqldf("select DepDelay,DayOfWeek,UniqueCarrier,Origin,Dest,DestState,DepTime,Cancelled,CarrierDelay, WeatherDelay, NASDelay, SecurityDelay,
LateAircraftDelay from time where DepDelayMinutes > 0 and Origin = 'SFO'")
# get data for most common delay
delay.lr <- sqldf("select DepDelay, DayOfWeek, DepTime, Cancelled, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay
FROM delay")
delay.carrier <- sqldf("select DepDelay,Carrier from time where DepDelayMinutes > 0 and Origin = 'SFO'")
#find the carrier names
setwd("C:/Users/jaturman/Desktop/804w/Midterm")
carrier.delay <- read.csv("DelayByCarrier")
# assign columns to vectors
aa <- c(carrier.delay$AA)
as <- c(carrier.delay$AS)
b6 <- c(carrier.delay$B6)
dl <- c(carrier.delay$DL)
oo <- c(carrier.delay$OO)
ua <- c(carrier.delay$UA)
vx <- c(carrier.delay$VX)
wn <- c(carrier.delay$WN)
ev <- c(carrier.delay$EV)
f9 <- c(carrier.delay$F9)
ha <- c(carrier.delay$HA)
nk <- c(carrier.delay$NK)
# format data into groups
total <- c(aa,as,b6,dl,oo,ua,vx,wn,ev,f9,ha,nk)
n <- rep(1000,12)
group <- rep(c('AA','AS','B6','DL','OO','UA','VX','WN','EV','F9','HA','NK'),n)
# descriptive stats of data set for anova
tmp = function(x) c(sum=sum(x), mean = mean(x), median=median(x), mode = mode(x), var=var(x), sd = sd(x),
n = length(x), kurtosis=kurtosis(x),skew = skewness(x), max = max(x), min = min(x), range = max(x)-min(x),
quartiles = quantile(x),iqr =IQR(x))
tapply(total,group,tmp)
View(carrier.delay)
describe(delay.lr)
View(carrier.delay)
View(delay)
View(delay.carrier)
View(delay.lr)
count.cd = 0
for (i in delay$CarrierDelay){
if (i != 0 && !is.na(i)){
count.cd <- count.cd + 1
}
}
cat("Number of carrier delays: ",count.cd)
#number of weather delays
count.wd = 0
for (i in delay$WeatherDelay){
if (i != 0 && !is.na(i)){
count.wd <- count.wd + 1
}
}
cat("Number of weather delays: ",count.wd)
# number of NAS delays
count.nd = 0
for (i in delay$NASDelay){
if (i != 0 && !is.na(i)){
count.nd <- count.nd + 1
}
}
cat("Number of NAS delays: ",count.nd)
# number of security delays
count.sd = 0
for (i in delay$SecurityDelay){
if (i != 0 && !is.na(i)){
count.sd <- count.sd + 1
}
}
cat("Number of security delays: ",count.sd)
# number of late aircraft delays
count.ad = 0
for (i in delay$LateAircraftDelay){
if (i != 0 && !is.na(i)){
count.ad <- count.ad + 1
}
}
cat("Number of aircraft delays: ",count.ad)
delay.log <- sqldf("select ArrDelay, case when Carrier = 'AA' then 1
when Carrier = 'AS' then 2
when Carrier = 'B6' then 3
when Carrier = 'DL' then 4
when Carrier = 'UA' then 5
when Carrier = 'OO' then 6
when Carrier = 'VX' then 7
when Carrier = 'WN' then 8
when Carrier = 'F9' then 9
when Carrier = 'HA' then 10
End as Carrier, DepDelay, TaxiOut, Distance, AirTime,
CarrierDelay, WeatherDelay,
NASDelay, SecurityDelay,LateAircraftDelay
from time where Origin = 'SFO'")
delay.log[is.na(delay.log)] <- 0
DelayModel <- delay.log
rownames(DelayModel) <- NULL
write.csv(DelayModel, file = "DelayModelFields")
pred.mod <- read.csv("DelayModelFields")
model.dat <- pred.mod[-1]
data <- data.frame(total=total, group = factor(group))
fit <- lm(total~group, data)
carrier.delay.aov <- aov(fit)
carrier.delay.aov.summary <- summary(carrier.delay.aov)
print(carrier.delay.aov.summary)
qqnorm(total)
carrier.lev <- leveneTest(total~group,data=data)
print(carrier.lev)
carrier.tukey <- TukeyHSD(carrier.delay.aov)
print(carrier.tukey)
plot(carrier.tukey)
total <- c(aa,as,b6,dl,oo,ua,vx,wn,ev,f9,ha,nk)
n <- rep(1000,12)
group <- rep(c('AA','AS','B6','DL','OO','UA','VX','WN','EV','F9','HA','NK'),n)
# descriptive stats of data set for anova
tmp = function(x) c(sum=sum(x), mean = mean(x), median=median(x), mode = mode(x), var=var(x), sd = sd(x),
n = length(x), kurtosis=kurtosis(x),skew = skewness(x), max = max(x), min = min(x), range = max(x)-min(x),
quartiles = quantile(x),iqr =IQR(x))
tapply(total,group,tmp)
model.out <- summary(regsubsets(x, y, nbest = 1, nvmax = ncol(x),force.in = NULL, force.out = NULL, method = "exhaustive"))
model.regtab <- cbind(model.out$which,model.out$rsq, model.out$adjr2, model.out$cp) # Stich things together
colnames(model.regtab) <- c("(Intercept)","Carrier","DepDelay","TaxiOut", "Distance", "AirTime", "CarrierDelay","WeatherDelay","NASDelay",
"SecurityDelay","LateAircraftDelay", "R-Sq", "R-Sq (adj)", "Cp") # Add header
print(model.regtab)
pred.mod <- read.csv("DelayModelFields")
model.dat <- pred.mod[-1]
#model.dat$ArrDelay <- as.factor(model.dat$ArrDelay)
x <- model.dat[,2:11]
y <- model.dat[,1]
model.out <- summary(regsubsets(x, y, nbest = 1, nvmax = ncol(x),force.in = NULL, force.out = NULL, method = "exhaustive"))
model.regtab <- cbind(model.out$which,model.out$rsq, model.out$adjr2, model.out$cp) # Stich things together
colnames(model.regtab) <- c("(Intercept)","Carrier","DepDelay","TaxiOut", "Distance", "AirTime", "CarrierDelay","WeatherDelay","NASDelay",
"SecurityDelay","LateAircraftDelay", "R-Sq", "R-Sq (adj)", "Cp") # Add header
print(model.regtab)
delay.lr <- lm(ArrDelay ~ ., data = model.dat)
delay.lr.summary <- summary(delay.lr)
print(delay.lr.summary)
View(model.dat)
setwd("C:/Users/jaturman/Desktop/804w/Midterm")
setwd("C:/Users/jaturman/Desktop/data analysis/ops804/Midterm/data")
setwd("C:/Users/jaturman/Desktop/804w/Midterm")
setwd("C:/Users/jaturman/Desktop/804w/Midterm")
plot1 <- ggplot(delay.lr, aes(x = .fitted, y = .resid)) +
geom_point() +
stat_smooth(method = "loess") +
geom_hline(yintercept = 0, col = "red", linetype = "dashed") +
xlab("Fitted values") +
ylab("Residuals") +
ggtitle("Residual vs Fitted Plot")
plot2 <- ggplot(delay.lr, aes(x = qqnorm(.stdresid)[[1]], y = .stdresid)) +
geom_point(na.rm = TRUE) +
geom_abline() +
xlab("Theoretical Quantiles") +
ylab("Standardized Residuals") +
ggtitle("Normal Q-Q")
delay.skew <- skewness(delay.lr$.resid)
delay.kurt <- kurtosis(delay.lr$.resid)
## Equal variance
### Scale-Location Plot
plot3 <- ggplot(delay.lr, aes(x = .fitted, y = sqrt(abs(.stdresid)))) +
geom_point(na.rm=TRUE) +
stat_smooth(method = "loess", na.rm = TRUE) +
xlab("Fitted Value") +
ylab(expression(sqrt("|Standardized residuals|"))) +
ggtitle("Scale-Location")
## Independence
# Perform a Durbin-Watson F-test for autocorrelation
##toy.g.dw <- dwtest(m1)
## Outlier influance
### Cook's Distance Histogram
plot4 <- ggplot(delay.lr, aes(x =.hat, y = .stdresid)) +
geom_point(aes(size=.cooksd), na.rm=TRUE) +
stat_smooth(method="loess", na.rm=TRUE) +
xlab("Leverage") +
ylab("Standardized Residuals") +
ggtitle("Residual vs Leverage Plot") +
scale_size_continuous("Cook's Distance", range = c(1,5)) +theme(legend.position="bottom")
print(plot1)
print(plot2)
print(plot3)
print(plot4)
## Save Plots
ggsave("linearityAssumption.pdf", plot1)
ggsave("normalityAssumption.pdf", plot2)
ggsave("equalVarianceAssumptions.pdf", plot3)
ggsave("outlierInfluance1Assumptions.pdf", plot4)
View(data)
